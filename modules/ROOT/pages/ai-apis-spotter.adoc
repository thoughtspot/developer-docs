= Spotter AI APIs [beta betaBackground]^Beta^
:toc: true
:toclevels: 2

:page-title: AI APIs
:page-pageid: ai-apis
:page-description: You can use Spotter REST APIs to receive Answers for your analytical queries sent  through the conversational experience with ThoughtSpot.

The AI APIs [beta betaBackground]^Beta^  enable agentic conversational analytics by allowing users and systems to interact with data using natural language. These APIs collectively enable natural language interaction, context-aware analytics, and guided data analysis.

Each of these APIs serves a specific function:

*  `POST /api/rest/2.0/ai/agent/conversation/create` +
Creates a new AI-driven conversation session based on a specified data source. The resulting session sets the context for subsequent queries and responses.  +
__Available on ThoughtSpot Cloud instances from 10.13.0.cl onwards__.

* `POST /api/rest/2.0/ai/data-source-suggestions` +
Returns a list of relevant data sources, such as Models, based on a query and thus helping users and agents choose the most appropriate data source for analytics. +
__Available on ThoughtSpot Cloud instances from 10.13.0.cl onwards__.

* `POST /api/rest/2.0/ai/relevant-questions/` +
Breaks down a user-submitted query into a series of analytical sub-questions using relevant contextual metadata. Provides a list of recommended or relevant questions for a given data source and conversation context to allow users to explore their data further.  +
__Available on ThoughtSpot Cloud instances from 10.13.0.cl onwards__.

* `POST /api/rest/2.0/ai/agent/conversation/converse` +
Allows sending a follow-up message or question to an ongoing conversation session and returns the AI agent's response, including answers, tokens, and visualization details.  +
__Available on ThoughtSpot Cloud instances from 10.13.0.cl onwards__.

* `POST /api/rest/2.0/ai/answer/create` +
Allows users to submit a natural language search query and returns a AI-generated chart or table in response. +
__Available on ThoughtSpot Cloud instances from 10.4.0.cl onwards__.
 It requires at least view access to the relevant metadata object and is available in ThoughtSpot Cloud version 10.4.0.cl or later.


[IMPORTANT]
====
The `/api/rest/2.0/ai/conversation/create`, `/api/rest/2.0/ai/conversation/{conversation_identifier}/converse`, and `/api/rest/2.0/ai/analytical-questions` are deprecated and will be removed from the REST API Playground in an upcoming release. When your instance is upgraded to 10.13.0.cl, use the new API endpoints.

* To create a conversation session, use `/api/rest/2.0/ai/agent/conversation/create` instead of `/api/rest/2.0/ai/conversation/create`.
* To send a follow-up question to an ongoing conversation session, use `/api/rest/2.0/ai/agent/conversation/converse` instead of `/api/rest/2.0/ai/conversation/{conversation_identifier}/converse`.
* To breakdown user-submitted query and generate relevant questions, use `POST /api/rest/2.0/ai/relevant-questions/` instead of `POST /api/rest/2.0/ai/analytical-questions`.
====

== Create a conversation session

The `/api/rest/2.0/ai/agent/conversation/create` API endpoint allows you to initiate a new conversation session with the ThoughtSpot AI analyst, Spotter. The conversation session acts as a container for maintaining continuity across user inputs and system responses, and agent-driven clarifications. Once created, users can send follow-up questions to this conversation session to explore data and get further insights.

Developers and system integrators embedding Spotter into agentic workflows, custom applications, or internal MCP (Managed Content Platform) servers, can use this API.

[NOTE]
====
You must have at least view access to the objects specified in the API request to create a conversation context and use it for subsequent queries.
====

=== Request parameters
To set the context for the conversation session, you must specify the metadata type and context in the `POST1 request body. Optionally, you can also define additional parameters to fine tune the context and generate accurate and precise responses.

[width="100%" cols="2,4"]
[options='header']
|=====
|Parameter| Description
|`metadata_context` a| Defines the data context for the conversation. Specify the following values:

* `type` +
Metadata type. Valid values are:
** `answer`  - To use an existing Spotter-generated Answer as the object
** `liveboard` - To use an existing Liveboard as data object
** `data_source` - To create a new conversation session using data objects such as Model.
+

* `answer_context` +
If the metadata type is set as `answer`, specify the following attributes:
** `session_identifier`: __string__, Unique ID representing the answer session.
** `generation_number`: __Integer__. Specific generation/version number of the answer within a conversation session.
+
The session identifier and generation numbers are generated when an Answer object is created from a Spotter query. These properties are returned in the API response when you generate an Answer from a Spotter query via `/api/rest/2.0/ai/answer/create` API call.

* `liveboard_context` +
If the metadata type is set as `liveboard`, specify the GUID of the Liveboard and visualization.
* `data_source_context` +
If the metadata type is set as `data_source`, specify the GUID of the data source object.

|`conversation_settings` |__Optional__.  Defines additional parameters for the conversation context. You can set any of the following attributes as needed:

* `enable_contextual_change_analysis` +
__Boolean__. When enabled, Spotter analyzes how context changes over time, that is comparing results from different queries.
* `enable_natural_language_answer_generation` +
__Boolean__. Allows sending natural language queries to the conversation session.
* `enable_reasoning` +
__Boolean__. Allows Spotter to use reasoning for deep analysis and precise responses.
|=====

=== Example

[source,cURL]
----
curl -X POST \
  --url 'https://{ThoughtSpot-Host}/api/rest/2.0/ai/agent/conversation/create'  \
  -H 'Accept: application/json' \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer {AUTH_TOKEN}' \
  --data-raw '{
  "metadata_context": {
    "type": "data_source",
    "data_source_context": {
      "guid": "cd252e5c-b552-49a8-821d-3eadaa049cca"
    }
  },
  "conversation_settings": {
    "enable_contextual_change_analysis": false,
    "enable_natural_language_answer_generation": true,
    "enable_reasoning": false
  }
}'
----

=== Example response

If the API request is successful, the API returns the conversation ID. You can use this ID to send follow-up questions to the conversation session.

[source,JSON]
----
{"conversation_id":"q9tZYf_6WnFC"}
----

=== Send queries to a conversation session

To send queries to an ongoing conversation, send `POST` request body with conversation ID and the query string to the `POST /api/rest/2.0/ai/agent/conversation/conversee` API endpoint.

==== Request parameters

[width="100%" cols="2,4"]
[options='header']
|=====
|Parameter| Description
|`conversation_identifier` |__String__. Specify the GUID of the conversation received from the xref:ai-apis-spotter.adoc#_create_a_conversation_session[create conversation API call].
|`message`|_Array of Strings_. Specify the queries in natural language. For example, `Sales data for Jackets`, `Top performing products in the west coast`.
|`settings` |__Optional__.  Defines additional parameters for the conversation context. You can set any of the following attributes as needed:

* `enable_contextual_change_analysis` +
__Boolean__. When enabled, Spotter analyzes how the context changes over time, that is comparing results from different queries.
* `enable_natural_language_answer_generation` +
__Boolean__. Allows sending natural language queries to the conversation session.
* `enable_reasoning` +
__Boolean__. Allows Spotter to use reasoning for deep analysis and precise responses.

|=====

==== Example request

[source,cURL]
----
curl -X POST \
  --url 'https://{ThoughtSpot-Host}/api/rest/2.0/ai/agent/conversation/converse'  \
  -H 'Accept: application/json' \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer {AUTH_TOKEN}' \
  --data-raw '{
    "input": {
      "conversation_identifier": "q9tZYf_6WnFC",
      "messages": [
        "Net sales for this year compared to last year based on the last reorder date"
      ],
    "settings": {
      "enable_contextual_change_analysis": false,
      "enable_natural_language_answer_generation": false,
      "enable_reasoning": false
    }
  }
}'
----

==== API response

If the API request is successful, the API returns a stream of messages:

* `ack` +
Confirms receipt of the request
* `text / text-chunk` +
Content chunks, optionally formatted (for example, markdown)
- `answer` +
The final structured response with metadata and analytics
- `error` +
Indicates failure.
- `notification` +
Notification messages for operation being performed

The following example shows the API response returned for a Spotter query:

[source,JSON]
----
[
  {
    "id": "6JSiAI1C5OK5",
    "type": "answer",
    "group_id": "W_qnpv8K6z9j",
    "metadata": {
      "sage_query": "[Net Sales] [last_reorderdate] = 'this year' vs [last_reorderdate] = 'last year'",
      "session_id": "461863f9-38ca-45e3-beba-ec72ec3841d9",
      "gen_no": 2,
      "transaction_id": "24e983d4-4ae4-44ce-a9d6-b42cdf006257",
      "generation_number": 1,
      "warning_details": null,
      "ambiguous_phrases": null,
      "query_intent": null,
      "tml_phrases": [
        "[Net Sales]",
        "[last_reorderdate] = 'this year' vs [last_reorderdate] = 'last year'"
      ],
      "cached": true,
      "sub_queries": null,
      "title": "Untitled",
      "worksheet_id": "cd252e5c-b552-49a8-821d-3eadaa049cca"
    },
    "title": "Untitled"
  }
]
----

The API response returns the session ID, generation number, tokens for search query, and TML phrases for the following information when the query generates an Answer. This information can be used to generate a chart or table via `POST /api/rest/2.0/ai/answer/create` API call.

////
* `type` +
Type of the response. For Spotter-generated Answers, the type is set as `answer`.
* `session_id` +
GUID of the Answer session.
* `generation_number` +
Number assigned to the Answer session.
* `message_type`
Type of response received for the query. For example, `TSAnswer` (ThoughtSpot Answer).
* `visualization_type`
The data format of the generated Answer; for example, chart or table. When you download this Answer, the data will be exported in the format indicated by the `visualization_type`.
* `sage_query` +
Tokens generated from the natural language search query string specified in the API request. You can use these tokens as input for `query_string` in your API request to `/api/rest/2.0/searchdata` and  export the raw data of the query.  or as input to `POST /api/rest/2.0/ai/conversation/create` to initiate a new conversation with a new context.
* tml_phrases


[NOTE]
====
Note the session ID and generation number. To export the Answer generated from this conversation, send these attributes in the `POST` request body to the `/api/rest/2.0/report/answer` endpoint.
====

[source,JSON]
----
[
  {
    "session_identifier": "1290f8bc-415a-4ecb-ae3b-e1daa593eb24",
    "generation_number": 3,
    "message_type": "TSAnswer",
    "visualization_type": "Chart",
    "tokens": "[sales], [state], [item type], [region] = [region].'west', sort by [sales] descending"
  }
]
----
////

==== Ask follow-up questions

You can send another API request with a follow-up question to the same conversation ID. The API retains the context of previous queries when you send follow-up questions.

[source,cURL]
----
curl -X POST \
  --url 'https://{ThoughtSpot-Host}/api/rest/2.0/ai/conversation/03f48527-b973-4efa-81fd-a8568a4f9e78/converse'  \
  -H 'Accept: application/json' \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer {AUTH_TOKEN}' \
  --data-raw '{
  "metadata_identifier": "cd252e5c-b552-49a8-821d-3eadaa049cca",
  "message": "which city has the better sales of jackets here?"
}'

curl -X POST \
  --url 'https://{ThoughtSpot-Host}/api/rest/2.0/ai/agent/conversation/converse'  \
  -H 'Accept: application/json' \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer {AUTH_TOKEN}' \
  --data-raw '{
    "input": {
      "conversation_identifier": "q9tZYf_6WnFC",
      "messages": [
        "Net sales of Jackets for this year compared to last year"
      ],
    "settings": {
      "enable_contextual_change_analysis": false,
      "enable_natural_language_answer_generation": false,
      "enable_reasoning": false
    }
  }
}'
----

The API retrains the context of the initial question and returns a response accordingly:

////
[source,JSON]
----
[
  {
    "session_identifier": "ee077665-08e1-4a9d-bfdf-7b2fe0ca5c79",
    "generation_number": 3,
    "message_type": "TSAnswer",
    "visualization_type": "Table",
    "tokens": "[sales], by [city], [state], [item type] = [item type].'jackets', [region] = [region].'west', sort by [sales] descending"
  }
]
----
===== Response codes
[width="100%" cols="2,4"]
[options='header']
|===
|HTTP status code|Description
|**200**| Successful operation
|**400**| Invalid parameter
|**401**| Unauthorized access
|**500**| Internal error
|===
////

== Get data source suggestions

The `POST /api/rest/2.0/ai/data-source-suggestions` API provides relevant data source recommendations for a user-submitted natural language query. To use this API, you must have at least view access to the underlying metadata source referenced in the response.

=== Example request

[source,JSON]
----
curl -X POST \
  --url 'https://{ThoughtSpot-Host}/api/rest/2.0/ai/data-source-suggestions'  \
  -H 'Accept: application/json' \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer {AUTH_TOKEN}' \
  --data-raw '{
  "query": "Total sales by region"
}'
----

=== Example response
If the API request is successful, ThoughtSpot returns a ranked list of data sources, each annotated with relevant reasoning.

[source,JSON]
----
{
  "data_sources": [
    {
      "confidence": 0.95,
      "details": {
        "description": "",
        "data_source_name": "(Sample) Retail - Apparel",
        "data_source_identifier": "cd252e5c-b552-49a8-821d-3eadaa049cca"
      },
      "reasoning": ""
    },
    {
      "confidence": 0.93,
      "details": {
        "description": "",
        "data_source_name": "X-Store-model",
        "data_source_identifier": "4ba38739-d905-4dd2-9184-8771d5245044"
      },
      "reasoning": ""
    },
    {
      "confidence": 0.91,
      "details": {
        "description": "",
        "data_source_name": "Sales_WS",
        "data_source_identifier": "bd1d48e0-a9ea-4497-bf16-1961c310a3d1"
      },
      "reasoning": ""
    }
  ]
}
----

The returned results include metadata such as:

* `confidence` +
A float indicating the model's confidence in the relevance of each recommendation
* `details` +
Includes `data_source_identifier`, `data_source_name`, and description of each recommended data
source
* `reasoning` +
Rationale provided by the LLM to explain why each data source was recommended

== Get relevant questions

The API breaks down a user-submitted query into a structured set of analytical sub-questions, leveraging relevant contextual metadata to enhance accuracy and relevance.


=== Request parameters
[cols="1,1,2,2"]
|===
|Name |Type |Required |Description

|dataSource
|string
|Yes
|GUID of the worksheet or model.

|conversationId
|string
|No
|Ongoing conversation session ID.

|limit
|integer
|No
|Maximum number of questions to return.

|===


* limit_relevant_questions (integer, default: 5)
 Controls the maximum number of relevant questions returned. Sets a cap on the number of sub-questions returned in the response. Defaults to 5 if not specified.
* bypass_cache (boolean)
If set to true, disables cache and forces fresh computation.
* +context +
** instructions (array of strings)
Custom user instructions to influence how the AI interprets and processes the query.
** content (array of strings)
Additional input such as raw text or CSV-formatted data to enhance context and answer quality.

=== Example request
[source,json]
----
{
  "dataSource": "12345678-aaaa-bbbb-cccc-1234567890ab",
  "limit": 3
}
----
* metadata (object)
Provides contextual metadata to guide sub-question generation. Must include at least one identifier (e.g., data source, answer, conversation, or liveboard).
* query (string)
The main user query to be decomposed into smaller, analytical sub-questions for improved understanding and structured responses.

=== Example response

[source,JSON]
----
{
"relevant_questions": [
{
"query": "string" | null,
"data_source_identifier": "string" | null,
"data_source_name": "string" | null
}
]
}
----

The response object contains a single top-level field:

* relevant_questions
It contains the list of sub-questions that have been generated from the user’s original query. Each question in this list is tied to a specific data source and can be executed using a natural language search interface. This field is nullable, meaning it may be +null+ if no relevant sub-questions were identified during processing.

Each object in the +relevant_questions+ array contains the following fields:

* query
A string containing the natural language (NL) sub-question.
* data_source_identifier
A string representing the unique identifier of the data source on which this sub-question is intended to be executed.
* data_source_name
name of the associated data source.

////
== Get data source suggestions
///





=== Send message

`POST /api/rest/2.0/ai/agent/conversation/converse`

Purpose::
Send a message to an ongoing agent conversation and receive a response.

.Parameters
[cols="1,1,2,2"]
|===
|Name |Type |Required |Description

|conversationId
|string
|Yes
|Conversation session ID.

|message
|string
|Yes
|User’s message.

|context
|object
|No
|Additional context for the message.

|context.tokens
|array of string
|No
|Context tokens.
|===

.Limitations and Functional Impacts
* Only valid, active conversation IDs are accepted.
* Message length may be limited; long messages may be truncated.
* Visualization types and data returned depend on the data source and agent capabilities.
* If Spotter is not enabled, the endpoint is non-functional.
* High concurrency or large data sources may impact response latency.
* If ABAC is enabled, some features may be restricted or less accurate.

.Example Request
[source,json]
----
{
  "conversationId": "conv-abcdef123456",
  "message": "Show me sales for last quarter",
  "context": {
    "tokens": ["[sales]", "[last quarter]"]
  }
}
----

.Example Response
[source,json]
----
{
  "conversationId": "conv-abcdef123456",
  "answer": "Here are the sales for last quarter by region.",
  "visualizationType": "bar_chart",
  "visualizationData": { /* chart data */ },
  "tokens": ["[sales]", "[last quarter]"]
}
----

==== Overview

 *Purpose*:
The API allows users to initiate or continue an Spotter agent conversation by submitting one or more natural language messages.
 *Authentication:*
This endpoint requires https://rest-api-sdk-v2-0-dev.vercel.app/?auth_token=eyJ0eXBlIjoiSldUIiwiYWxnIjoiSFMyNTYifQ.eyJiYXNlLXVybCI6ImxvY2FsaG9zdDo0NDMiLCJuYW1lIjoiT3dsYmVydCIsImFsbG93ZWRQcm9qZWN0cyI6WyJ0ZXN0LXRzLWpzbnRtIl0sImJlYXJlckF1dGgiOiJaR1Z0YjE5a1pYWjFjMlZ5T2twSVRtOWhXRXAyVFZOU1ZGTkZSWFJOYWxVeVNrUlZkMDFFUVhkTlExSk9XakJ2TUdSNlRqQlVSRlpNVFZaV1dscEZORFJUTTFaelZVaGtibEJVTUd0T2JXUnVWa2RPUkdSR1NsWmFTRlkyWlVSR00yVkVTVFZqYlRWWFlXMW9ZV016V1hoV01ITXlTekZPTkU5RVdrWlphbVJYVWtkSk1XUjZNQT09IiwidmVyc2lvbiI6MSwiZW1haWwiOiJvd2xiZXJ0QHJlYWRtZS5jb20ifQ.VxWcxbliJMiuSbaozoLDp0EVexv4smISkp4HtlwKK_w#/http/api-endpoints/ai/$h/__auth_BearerAuth[bearerAuth]

=== Request/Response

==== Request

* *Method*: POST
* *Endpoint*: +POST++ ++/api/rest/2.0/ai/agent/conversation/send_message++
+
* *Headers*:
Authorization: Bearer <token>
Content-Type: application/json







* *Request Body Schema*:
{
  "conversation_identifier": "string",
  "messages": [
    {
      "value": "string",
      "type": "text"
    }
  ],
  "settings": {
    "enable_contextual_change_analysis": false,
    "enable_natural_language_answer_generation": true,
    "enable_reasoning": false
  },
  "runtime_params": {
	runtime_filter: [],
	runtime_param: [],
  }
}


===== Request Body Fields:


* conversation_identifier: Unique ID representing the conversation session.
* messages: List of user messages, each with content and a message type.
* settings: Flags to enable or disable specific assistant response features.
* runtime_params: Optional parameters to customize runtime behavior or model execution. (can be kept hidden for v1 as)

==== Response

* *Success Response*:
[{
	type: ack
	node_id: str # response node id
},
{
	type: text / text-chunk
	id: str
	group_id: str
	content: str
	metadata: {
format: markdown / html
       }
},
{
	type: answer
	id: str
	group_id: str
title:
	description:
	session_id:
	gen_no:
	sage_query:
	formulas: []
	metadata: {}

},
{
	type: error
	id: str
	group_id: str
	code: str
	message: str
	metadata: {}
},
{
	type: notification
	id: str
	group_id: str
	code: str
	message: str
	metadata: {}
}]



Each object in the response stream represents a distinct message type used to update the client progressively during a conversation or computation.


==== Acknowledgement Message (type: "ack")


{
  "type": "ack",
  "node_id": "string"
}

==== Text Message (type: "text" or "text-chunk")


{
  "type": "text",  // or "text-chunk"
  "id": "string",
  "group_id": "string",
  "content": "string",
  "metadata": {
    "format": "markdown" // or "html"
  }
}

==== Answer Message (type: "answer")


{
  "type": "answer",
  "id": "string",
  "group_id": "string",
  "title": "string",
  "description": "string",
  "session_id": "string",
  "gen_no": "integer",
  "sage_query": "string",
  "formulas": [],
  "metadata": {}
}

==== Error Message (type: "error")


{
  "type": "error",
  "id": "string",
  "group_id": "string",
  "code": "string",
  "message": "string",
  "metadata": {}
}


=== Sample Request & Response

==== Request

{
  "conversation_identifier": "abc123-session-id",
  "messages": [
    {
      "value": "compare this year's sales with last year",
      "type": "text"
    }
  ],
  "settings": {
    "enable_contextual_change_analysis": false,
    "enable_natural_language_answer_generation": true,
    "enable_reasoning": false
  },
}

==== Response

[source,JSON]
----
data: [{"type": "ack", "node_id": "i9-dgf6QUx4z"}]

data: [{"type": "notification", "group_id": "W_qnpv8K6z9j", "metadata": {"title": "Compare this year's sales with last year"}, "code": "nls_start"}]

data: [{"type": "notification", "group_id": "W_qnpv8K6z9j", "code": "QH", "message": "Fetching Worksheet Data"}]

data: [{"type": "notification", "group_id": "W_qnpv8K6z9j", "code": "TML_GEN", "message": "Translating your query with the Reasoning Engine"}]

data: [{"type": "notification", "group_id": "W_qnpv8K6z9j", "code": "ANSWER_GEN", "message": "Verifying results with the Trust Layer"}]

data: [{"id": "6JSiAI1C5OK5", "type": "answer", "group_id": "W_qnpv8K6z9j", "metadata": {"sage_query": "[Net Sales] [last_reorderdate] = 'this year' vs [last_reorderdate] = 'last year'", "session_id": "461863f9-38ca-45e3-beba-ec72ec3841d9", "gen_no": 2, "transaction_id": "24e983d4-4ae4-44ce-a9d6-b42cdf006257", "generation_number": 1, "warning_details": null, "formulas": [{"name": "DiffYears(last_reorderdate, Today(), bfa39848-ba4f-46d8-80fd-b695064e61b7) = 0 OR DiffYears(last_reorderdate, Today(), bfa39848-ba4f-46d8-80fd-b695064e61b7) = -1", "expression": "diff_years ( last_reorderdate , today ( ) , fiscal ) = 0 or diff_years ( last_reorderdate , today ( ) , fiscal ) = - 1"}, {"name": "Net Sales(last_reorderdate = this year)", "expression": "group_aggregate ( sum ( Net Sales ) , query_groups ( ) , query_filters ( ) + { diff_years ( last_reorderdate , today ( ) , fiscal ) = 0 } )"}, {"name": "Net Sales(last_reorderdate = last year)", "expression": "group_aggregate ( sum ( Net Sales ) , query_groups ( ) , query_filters ( ) + { diff_years ( last_reorderdate , today ( ) , fiscal ) = - 1 } )"}, {"name": "Net Sales(last_reorderdate = last year)", "expression": "group_aggregate ( sum ( Net Sales ) , query_groups ( ) , query_filters ( ) + { diff_years ( last_reorderdate , today ( ) , fiscal ) = -1 } )"}, {"name": "Net Sales(last_reorderdate = this year)", "expression": "group_aggregate ( sum ( Net Sales ) , query_groups ( ) , query_filters ( ) + { diff_years ( last_reorderdate , today ( ) , fiscal ) = 0 } )"}, {"name": "DiffYears(last_reorderdate, Today(), bfa39848-ba4f-46d8-80fd-b695064e61b7) = 0 OR DiffYears(last_reorderdate, Today(), bfa39848-ba4f-46d8-80fd-b695064e61b7) = -1", "expression": "diff_years ( last_reorderdate , today ( ) , fiscal ) = 0 or diff_years ( last_reorderdate , today ( ) , fiscal ) = -1"}], "ambiguous_phrases": null, "query_intent": null, "tml_phrases": ["[Net Sales]", "[last_reorderdate] = 'this year' vs [last_reorderdate] = 'last year'"], "cached": true, "sub_queries": null, "title": "Untitled", "worksheet_id": "bd1d48e0-a9ea-4497-bf16-1961c310a3d1"}, "title": "Untitled"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "The"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " comparison"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " of"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " sales"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " between"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " this"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " year"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " and"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " last"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " year"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " shows"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": ":\n\n"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "-"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " **"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "Net"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " Sales"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " for"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " last"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " year"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "**"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": ":"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " "}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "15"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": ","}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "650"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": ","}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "609"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "."}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "63"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "\n"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "-"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " **"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "Net"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " Sales"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " for"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " this"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " year"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "**"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": ":"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " "}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "2"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": ","}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "495"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": ","}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "959"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "."}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "67"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "\n\n"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "This"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " indicates"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " a"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " significant"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " decrease"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " in"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " sales"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " this"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " year"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " compared"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " to"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " last"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " year"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "."}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " If"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " you'd"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " like"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": ","}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " I"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " can"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " analyze"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " the"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " reasons"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " behind"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " this"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " change"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " or"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " explore"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " specific"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " factors"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " contributing"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " to"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " the"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " decline"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "."}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " Let"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " me"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " know"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " how"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " you'd"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " like"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " to"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": " proceed"}]

data: [{"id": "jbiuKHCalt70", "type": "text-chunk", "group_id": "BZ2RvghK4Zez", "metadata": {"format": "markdown"}, "content": "!"}]
----

* Public Facing Documentation*

This API allows users to initiate or continue an Spotter agent conversation by submitting one or more natural language messages.
To use this API, the user must have access to the relevant conversational session (via conversation_identifier) and submit at least one message.
#### Usage guidelines
To initiate or continue a conversation, the request must include:
- `conversation_identifier`: a unique session ID for continuity and message tracking
- `messages`: an array of one or more text messages, each with a value and type
Additionally, user can specify what tool can be included `conversation_settings` parameter, which supports:
- `enable_contextual_change_analysis` (default: false)
- `enable_natural_language_answer_generation` (default: true)
- `enable_reasoning` (default: false)
If the request is valid, the API returns a stream of messages in real time, including:
- `ack`: confirms receipt of the request
- `text / text-chunk`: content chunks, optionally formatted (e.g., markdown)
- `answer`: the final structured response with metadata and analytics
- `error`: if a failure occurs
- `notification`: notification messages for operation being performed
> ###### Note:
> * This endpoint is currently in Beta. Breaking changes may be introduced before the endpoint is made Generally Available.
> * This endpoint requires Spotter - please contact ThoughtSpot support to enable Spotter on your cluster.
> * The streaming protocol uses Server-Sent Events (SSE)


==== API response

If the API request is successful, ThoughtSpot returns the Answer data for the query string sent in the API request.


===== Response codes
[width="100%" cols="2,4"]
[options='header']
|===
|HTTP status code|Description
|**200**| Successful operation
|**400**| Invalid parameter
|**401**| Unauthorized access
|**401**| Forbidden request
|**500**| Internal error
|===
////

== Generate a single Answer
To generate an Answer from a natural language search query, send a `POST` request to the `/api/rest/2.0/ai/answer/create` API endpoint. In the request body, include the query and the data source ID.

==== Request parameters

[width="100%" cols="2,4"]
[options='header']
|=====
|Form parameter| Description
|`query`|__String__. Required. Specify the string as a natural language query. For example, `Top performing products in the west coast`.
|`metadata_identifier`|_String_. Required. Specify the GUID of the ThoughtSpot Worksheet or Model. The metadata object specified in the API request will be used as a data source for the follow-up conversation.
|=====

==== Example request

[source,cURL]
----
curl -X POST \
  --url 'https://{ThoughtSpot-Host}/api/rest/2.0/ai/answer/create'  \
  -H 'Accept: application/json' \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer {AUTH_TOKEN} \
  --data-raw '{
  "query": "Top performing products in the west coast",
  "metadata_identifier": "cd252e5c-b552-49a8-821d-3eadaa049cca"
}'
----

==== API response

If the API request is successful, the following data is sent in the API response:

* `session_identifier` +
GUID of the Answer session.
* `generation_number` +
Number assigned to the Answer session.
* `message_type`
Type of response received for the query. For example, `TSAnswer` (ThoughtSpot Answer).
* `visualization_type`
The data format of the generated Answer; for example, chart or table. When you download this Answer, the data will be exported in the format indicated by the `visualization_type`.
* `tokens` +
Tokens generated from the natural language search query string specified in the API request. You can use these tokens as input for `query_string` in your API request to `/api/rest/2.0/searchdata` and  export the raw data of the query, or as input to `POST /api/rest/2.0/ai/conversation/create` to initiate a new conversation with a new context.

[NOTE]
====
Note the session ID and generation number. To export the result generated from this API call, send these attributes in the `POST` request body to the `/api/rest/2.0/report/answer` endpoint.
====

[source,JSON]
----
[{
  "session_identifier": "57784fa1-10fa-431d-8d82-a1657d627bbe",
  "generation_number": 2,
  "message_type": "TSAnswer",
  "visualization_type": "Undefined",
  "tokens": "[product], [region] = [region].'west', sort by [sales] descending"
}]
----